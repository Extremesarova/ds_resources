# Data Science Resources

For interview preparation and learning

**Table of Contents**:

- [Data Science Resources](#data-science-resources)
  - [Algorithms and Data Structures](#algorithms-and-data-structures)
  - [Python](#python)
  - [SQL](#sql)
  - [Machine Learning](#machine-learning)
  - [Deep Learning](#deep-learning)
  - [NLP](#nlp)
  - [Computer Vision](#computer-vision)
  - [Graphs](#graphs)
  - [Reinforcement Learning](#reinforcement-learning)
  - [RecSys](#recsys)
  - [Time Series](#time-series)
  - [Big Data](#big-data)

## Algorithms and Data Structures

<!-- omit in toc -->
### Platforms

- [LeetCode](https://leetcode.com/)
  - [Leetcode Patterns](https://seanprashad.com/leetcode-patterns/)  
  List of questions with patterns + tips
  - [LeetCode Explore](https://leetcode.com/explore/)  
- [Codewars](https://www.codewars.com/)  
- [HackerRank](https://www.hackerrank.com/)  
- [CodeAbbey](https://www.codeabbey.com/index/task_list)  
- [CodeRun](https://coderun.yandex.ru/catalog)
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –æ—á–Ω–æ–º—É —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é –≤ –Ø–Ω–¥–µ–∫—Å–µ. –ó–∞–¥–∞—á–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ –Ω–∞ —Ç–µ, —á—Ç–æ –±—É–¥—É—Ç –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é.
- [–î—Ä—É–≥–∏–µ](https://en.wikipedia.org/wiki/Competitive_programming#Online_platforms)  

<!-- omit in toc -->
### Courses

- [Algoprog](https://algoprog.ru/)  `paid`
- –Ø–Ω–¥–µ–∫—Å:
  - [–û—Å–Ω–æ–≤—ã –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ | –ê–∫–∞–¥–µ–º–∏—è –Ø–Ω–¥–µ–∫—Å–∞](https://academy.yandex.ru/handbook/algorithms)
  - [–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∫—É—Ä—Å ¬´–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–º—É —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é¬ª –æ—Ç –Ø–ü](https://practicum.yandex.ru/algorithms-interview/)
  - [–ö—É—Ä—Å ¬´–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö¬ª –æ—Ç –Ø–ü](https://practicum.yandex.ru/algorithms/) `paid`
  - [–ö—É—Ä—Å ¬´–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ–∏—Å–∫–∞¬ª](https://www.youtube.com/playlist?app=desktop&list=PLJOzdkh8T5koEPv-R5W0ovmL_T2BjB1HX)
- Computer Science Center:
  - [–ê–ª–≥–æ—Ä–∏—Ç–º—ã: —Ç–µ–æ—Ä–∏—è –∏ –ø—Ä–∞–∫—Ç–∏–∫–∞. –ú–µ—Ç–æ–¥—ã](https://stepik.org/course/217/info)  
  - [–ê–ª–≥–æ—Ä–∏—Ç–º—ã: —Ç–µ–æ—Ä–∏—è –∏ –ø—Ä–∞–∫—Ç–∏–∫–∞. –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö](https://stepik.org/course/1547/info)  
- [–ü–æ–¥–≥–æ—Ç–æ–≤—å—Å—è –∫ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–º—É —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é –∑–∞ 30 –Ω–µ–¥–µ–ª—å](https://balun.courses/courses/algorithmic_interview#program)  `paid`
- [Introduction To Algorithms by MIT](https://ocw.mit.edu/courses/6-006-introduction-to-algorithms-spring-2020/video_galleries/lecture-videos/) <!--- comment -->
- [Algorithms](https://cs50.harvard.edu/x/2024/weeks/3/) + [Data Structures](https://cs50.harvard.edu/x/2024/weeks/5/) from [CS50's Introduction to Computer Science](https://cs50.harvard.edu/x/2024/)  

<!-- omit in toc -->
### Resources

- –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞:
  - [–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞ 1](https://yandex.ru/yaintern/algorithm-training_1)
  - [–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞ 2](https://yandex.ru/yaintern/algorithm-training_2)
  - [–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞ 3](https://yandex.ru/yaintern/training/algorithm-training_3)
  - [–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞ 4](https://yandex.ru/yaintern/training/algorithm-training_4)
  - [–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞ 5](https://yandex.ru/yaintern/algorithm-training)
  - [–ò–Ω—Ç–µ–Ω—Å–∏–≤ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ—Ç –Ø–Ω–¥–µ–∫—Å–∞](https://www.youtube.com/playlist?list=PLQC2_0cDcSKAzLqqXUidKBJsy1Im44aOo)
- [Algorithmic concepts By Afshine Amidi and Shervine Amidi](https://superstudy.guide/algorithms-data-structures/foundations/algorithmic-concepts/)  
- [NeetCode. A better way to prepare for coding interviews.](https://neetcode.io/roadmap)  
- [The Algorithms. Open Source resource for learning Data Structures & Algorithms and their implementation in any Programming Language](https://github.com/TheAlgorithms)  
- [–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏](https://codonaft.com/%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B-%D0%B8-%D1%81%D1%82%D1%80%D1%83%D0%BA%D1%82%D1%83%D1%80%D1%8B-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%8B%D0%BC%D0%B8-%D1%81%D0%BB%D0%BE%D0%B2%D0%B0%D0%BC%D0%B8/)
- [–ê–ª–≥–æ—Ä–∏—Ç–º–∏–∫–∞](https://ru.algorithmica.org/)
- [Leetcode. Company-wise questions](https://github.com/MysteryVaibhav/leetcode_company_wise_questions)  
- [Code Abbey Problems](https://www.codeabbey.com/index/task_list)  
- [Unlocking Algorithm Efficiency: A Comprehensive Guide to Time and Space Complexity](https://deft1991.medium.com/unlocking-algorithm-efficiency-a-comprehensive-guide-to-time-and-space-complexity-42365215b1b7)  
- [Data Structures Reference](https://www.interviewcake.com/data-structures-reference)  
- [An Executable Data Structures Cheat Sheet for Interviews](https://algodaily.com/lessons/an-executable-data-structures-cheat-sheet)  
- [Coding Interview Guide](http://patrickhalina.com/posts/coding-interview-guide/)  
- [Algorithmic Thinking](https://labuladong.gitbook.io/algo-en/)  
- [Algorithm Notes](https://liuzhenglaichn.gitbook.io/algorithm/)  
- [Coding Interview University](https://github.com/jwasham/coding-interview-university/)  
- [Tech Interview Cheat Sheet](https://github.com/TSiege/Tech-Interview-Cheat-Sheet)  
- [Comprehensive Data Structure and Algorithm Study Guide](https://leetcode.com/discuss/general-discussion/494279/comprehensive-data-structure-and-algorithm-study-guide)  
- [Data Structures & Algorithms by Google](https://techdevguide.withgoogle.com/paths/data-structures-and-algorithms)  
- [Design and Analysis of Algorithms](https://eecs376.github.io/notes/algorithms.html)  
- [Algorithms for Competitive Programming](https://cp-algorithms.com/index.html)  

<!-- omit in toc -->
### Articles

- [–ö–∞–∫ –ø—Ä–æ—Ö–æ–¥—è—Ç –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ —Å–µ–∫—Ü–∏–∏ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è—Ö –≤ –Ø–Ω–¥–µ–∫—Å](https://habr.com/ru/companies/yandex/articles/449890/)
- [How to effectively use LeetCode to prepare for interviews](https://leetcode.com/discuss/career/449135/How-to-effectively-use-LeetCode-to-prepare-for-interviews)  

<!-- omit in toc -->
### Books

- [Grokking Algorithms. An illustrated guide for programmers and other curious people](https://www.manning.com/books/grokking-algorithms)
- [Elements of Programming Interviews in Python: The Insiders' Guide](https://www.amazon.com/Elements-Programming-Interviews-Python-Insiders/dp/1537713949/)
- [Cracking the Coding Interview: 189 Programming Questions and Solutions](https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850)
- [Problem Solving with Algorithms and Data Structures using Python by Brad Miller and David Ranum, Luther College](https://runestone.academy/ns/books/published/pythonds/index.html)
- [Competitive Programmer's Handbook by Antti Laaksonen](https://cses.fi/book/book.pdf)
- [Competitive Programming by Steven Halim](https://www.amazon.com/Competitive-Programming-4-Book-2/dp/B093K67NVN?crid=C4TR8FKXSWW1&keywords=competitive+programming+4&qid=1654975173&sprefix=competitive+programming+4,aps,131&sr=8-1&linkCode=sl1&tag=alexcancode0d-20&linkId=014a5744e277b65b2a6251d9884c031d&language=en_US&ref_=as_li_ss_tl)

## Python

<!-- omit in toc -->
### Clean Code

- [–ú–∞—Ä—Ç–∏–Ω –†. –ß–∏—Å—Ç—ã–π –∫–æ–¥: —Å–æ–∑–¥–∞–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥](https://www.piter.com/product/chistyy-kod-sozdanie-analiz-i-refaktoring-biblioteka-programmista-45ccca) / [Robert C. Martin. Clean Code: A Handbook of Agile Software Craftsmanship](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882)
- –°—Ç–∏–≤ –ú–∞–∫–∫–æ–Ω–Ω–µ–ª–ª. –°–æ–≤–µ—Ä—à–µ–Ω–Ω—ã–π –∫–æ–¥. –ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å / [Steve McConnell. Code Complete: A Practical Handbook of Software Construction](https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670)

<!-- omit in toc -->
### Theory

- [–û—Å–Ω–æ–≤—ã Python](https://education.yandex.ru/handbook/python)
- [Python: –æ—Å–Ω–æ–≤—ã –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ](https://stepik.org/course/512/info)
- [–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python](https://stepik.org/course/67/info)
- –ü–æ–∫–æ–ª–µ–Ω–∏–µ Python:
  - [–ö—É—Ä—Å –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö](https://stepik.org/course/58852)
  - [–ö—É—Ä—Å –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö](https://stepik.org/course/68343)
  - [–ö—É—Ä—Å –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–≤](https://stepik.org/course/82541)
- [CS50‚Äôs Introduction to Programming with Python](https://cs50.harvard.edu/python/2022/)  
- [CS50‚Äôs Introduction to Artificial Intelligence with Python](https://cs50.harvard.edu/ai/2024/) <!--- comment -->
- [Python Tutorial for Beginners (with mini-projects)](https://www.youtube.com/watch?v=qwAFL1597eM)  
- [What the f*ck Python! Exploring and understanding Python through surprising snippets](https://github.com/satwikkansal/wtfpython)  
- [Comprehensive Python Cheatsheet](https://github.com/gto76/python-cheatsheet)  
- [Python Koans. An interactive tutorial for learning the Python programming language by making tests pass](https://github.com/gregmalcolm/python_koans)  
- [Full Speed Python. Learning Python using a practical approach](https://github.com/joaoventura/full-speed-python?tab=readme-ov-file)
- [The Hitchhiker‚Äôs Guide to Python!](https://docs.python-guide.org)
- [A collection of design patterns and idioms in Python](https://github.com/faif/python-patterns)
- [Python Cheatsheet](https://www.pythoncheatsheet.org/cheatsheet/basics)

<!-- omit in toc -->
### Questions

- [53 Python Interview Questions and Answers](https://towardsdatascience.com/53-python-interview-questions-and-answers-91fa311eec3f)  
- Python: –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏:
  - [–ß–∞—Å—Ç—å I. Junior](<https://pythonist.ru/> python-voprosy-sobesedovaniya-chast-i-junior/)
  - [–ß–∞—Å—Ç—å II. Middle](https://pythonist.ru/python-voprosy-sobesedovaniya-chast-ii-middle/)
  - [–ß–∞—Å—Ç—å III. Senior](https://pythonist.ru/python-voprosy-sobesedovaniya-chast-iii-senior/)

<!-- omit in toc -->
### Other

- [Efficient Python Tricks and Tools for Data Scientists](https://khuyentran1401.github.io/Efficient_Python_tricks_and_tools_for_data_scientists/README.html) <!--- comment -->  

<!-- omit in toc -->
### Practice

- [–ó–∞–¥–∞—á–∏ –ø–æ Python –∏ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é](https://t.me/python_tasks)
- [Project Based Learning](https://github.com/practical-tutorials/project-based-learning#python)  
- [FastAPI Best Practices](https://github.com/zhanymkanov/fastapi-best-practices)

## SQL

- [How to pass data engineering SQL interviews in big tech](https://blog.dataengineer.io/p/how-to-pass-data-engineering-sql?utm_source=post-email-title&publication_id=1644342&post_id=136917153&utm_campaign=surfalytics.com)  

<!-- omit in toc -->
### Courses

- [–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–∞–∂–µ—Ä –ø–æ SQL](https://stepik.org/course/63054/info)
- [–ü–∞–∫–µ—Ç SQL –∫—É—Ä—Å–æ–≤](https://stepik.org/course/61247/info):
  - [–û—Å–Ω–æ–≤—ã SQL](https://stepik.org/course/51562/info)
  - [–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π SQL](https://stepik.org/course/55776/info)
  - [–ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö](https://stepik.org/course/51675/info)  
- [PostgreSQL Tutorial for Beginners](https://www.youtube.com/watch?v=SpfIwlAYaKk)
- [–û–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ SQL](https://stepik.org/course/95367/promo)
- [SQL Tutorial](https://mode.com/sql-tutorial/)  
- [The Ultimate SQL Guide](https://blog.count.co/the-ultimate-sql-guide/) <!--- comment -->

<!-- omit in toc -->
### Practice

- [–û–Ω–ª–∞–π–Ω —Ç—Ä–µ–Ω–∞–∂–µ—Ä SQL Academy](https://sql-academy.org/) <!--- comment -->
- [Ace the SQL Interview](https://datalemur.com/questions?category=SQL)  
- [Practice SQL](https://www.sql-practice.com/)  
- [SQLBolt. Learn SQL with simple, interactive exercises.](https://sqlbolt.com/)  
- [SQL Tutorial by w3schools](https://www.w3schools.com/sql/)  
- [PostgreSQL Exercises](https://pgexercises.com/)  
- [The Querynomicon. An Introduction to SQL for Wary Data Scientists](https://gvwilson.github.io/sql-tutorial/)  

## Machine Learning

<!-- omit in toc -->
### Sites

- [Machine Learning Mastery by Jason Brownlee](https://machinelearningmastery.com/) `paid`
- [–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ª—é–¥–µ–π. –†–∞–∑–±–∏—Ä–∞–µ–º—Å—è –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏](https://vas3k.blog/blog/machine_learning/)  <!--- comment -->
- [–ê–Ω–∞–ª–∏–∑ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö](https://dyakonov.org/ag/)
- [Kaggle Competitions](https://www.kaggle.com/competitions)  
- [The Illustrated Machine Learning](https://illustrated-machine-learning.github.io/)  
- [MLU-EXPLAIN](https://mlu-explain.github.io/)  

<!-- omit in toc -->
### Courses

- [Open Machine Learning Course](https://mlcourse.ai/book/index.html) by Yury Kashnitsky  <!--- comment -->
- [–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%BE) (–∫—É—Ä—Å –ª–µ–∫—Ü–∏–π, –ö.–í.–í–æ—Ä–æ–Ω—Ü–æ–≤)
- [–ü—Ä–∏–∫–ª–∞–¥–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö](https://github.com/Dyakonov/PZAD/tree/master) (–∫—É—Ä—Å –ª–µ–∫—Ü–∏–π, –ê.–ì.–î—å—è–∫–æ–Ω–æ–≤) [video](https://www.youtube.com/playlist?list=PLaRUeIuewv8CMFox0oEjlyePUhUmo-x0h)
- [–ê–ª–≥–æ—Ä–∏—Ç–º—ã –ú–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å –Ω—É–ª—è](https://stepik.org/course/68260/promo)
- [Stanford CS229: Machine Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) by Andrew Ng  <!--- comment -->
- [Kaggle Learn](https://www.kaggle.com/learn) <!--- comment -->
- [Google Machine Learning Courses](https://developers.google.com/machine-learning) <!--- comment -->
- [End to End Machine Learning by Brandon Rohrer](https://end-to-end-machine-learning.teachable.com/courses/) <!--- comment -->
- [–ú–∞—à–∏–Ω–Ω–æ–µ –û–±—É—á–µ–Ω–∏–µ –≤ Python: –ë–æ–ª—å—à–æ–π –ö—É—Ä—Å –¥–ª—è –ù–∞—á–∏–Ω–∞—é—â–∏—Ö](https://stepik.org/course/129449/info)  `paid`

<!-- omit in toc -->
### Books

- [–£—á–µ–±–Ω–∏–∫ –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –æ—Ç –®–ê–î](https://education.yandex.ru/handbook/ml/)
- [An Introduction to Statistical Learning](https://www.statlearning.com/) by Gareth James, Daniela Witten, Trevor Hastie, Rob Tibshirani  <!--- comment -->
- [The Elements of Statistical Learning](https://hastie.su.domains/Papers/ESLII.pdf) by Trevor Hastie, Robert Tibshirani, Jerome Friedman
- [Machine Learning Simplified: A gentle introduction to supervised learning](https://themlsbook.com/read) by Andrew Wolf  <!--- comment -->
- [The Kaggle Book](https://www.kaggle.com/discussions/general/320574)
- [Feature Engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/index.html) by Max Kuhn and Kjell Johnson  <!--- comment -->
- [Clean Machine Learning Code](https://leanpub.com/cleanmachinelearningcode)
- [Interpreting Machine Learning Models With SHAP: A Guide With Python Examples And Theory On Shapley Values](https://www.amazon.com/dp/B0CHL7W1DL)
- [Interpretable Machine Learning. A Guide for Making Black Box Models Explainable by Christoph Molnar](https://christophm.github.io/interpretable-ml-book/)
- [Machine Learning Q and AI. Expand Your Machine Learning & AI Knowledge With 30 In-Depth Questions and Answers by Sebastian Raschka](https://leanpub.com/machine-learning-q-and-ai/)
- [Reliable Machine Learning: Applying SRE Principles to ML in Production by Cathy Chen](https://www.amazon.com/Reliable-Machine-Learning-Principles-Production/dp/1098106229/ref=sr_1_9?crid=2LKWLWL9VVED7&keywords=SRE&qid=1677242699&sprefix=sre%2Caps%2C244&sr=8-9)
- [Machine Learning Refined: Foundations, Algorithms, and Applications](https://www.amazon.com/Machine-Learning-Refined-Foundations-Applications/dp/1107123526)
- [Models Demystified. A Practical Guide from t-tests to Deep Learning](https://m-clark.github.io/book-of-models/) by Michael Clark & Seth Berry

<!-- omit in toc -->
### Cheetsheets

- [Supervised Learning](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning)  
- [Unsupervised Learning](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning)  
- [Tips and Tricks](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks)  
- [Machine learning cheat sheet](https://github.com/soulmachine/machine-learning-cheat-sheet?tab=readme-ov-file)
- [Machine Learning Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/)

<!-- omit in toc -->
### Articles

- [Anthology of Modern Machine Learning](https://github.com/dmarx/anthology-of-modern-ml)
- [Cross-validation strategies for data with temporal, spatial, hierarchical, or phylogenetic structure](https://onlinelibrary.wiley.com/doi/10.1111/ecog.02881)
- [ML Papers of The Week by DAIR.AI](https://github.com/dair-ai/ML-Papers-of-the-Week)
- [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf)
- [Ilya 30u30](https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE)

<!-- omit in toc -->
### Applied ML

- [geographic Data Science with Python](https://geographicdata.science/book/notebooks/12_feature_engineering.html) <!--- comment -->
- [WTTE-RNN - Less hacky churn prediction](https://ragulpr.github.io/2016/12/22/WTTE-RNN-Hackless-churn-modeling/)
- [–ü—Ä–∏–∫–ª–∞–¥–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞—É–∫–∞—Ö](https://academy.yandex.ru/handbook/data-analysis?utm_source=vk&utm_medium=internal&utm_campaign=handbook_aon&utm_content=0606)
- [–ê–Ω—Å–∞–º–±–ª–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏](https://alexanderdyakonov.wordpress.com/2019/04/19/%D0%B0%D0%BD%D1%81%D0%B0%D0%BC%D0%B1%D0%BB%D0%B8-%D0%B2-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8/)
- [Reflecting on 18 years at Google](https://ln.hixie.ch/?start=1700627373&count=1)
- [Machine Learning for Imbalanced Data](https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data)
- [–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è](https://habr.com/ru/companies/glowbyte/articles/569970/)
- [Do Machine Learning Models Memorize or Generalize?](https://pair.withgoogle.com/explorables/grokking/)
- [Supervised Machine Learning for Science by Christoph Molnar & Timo Freiesleben](https://ml-science-book.com)

<!-- omit in toc -->
### Feature Engineering

- [–õ–µ–∫—Ü–∏—è –ø–æ –∫—É—Ä—Å—É –ú–ú–û - 24.03.2021, –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature selection)](https://www.youtube.com/watch?app=desktop&v=P7PhGneBFcI)
- [Kaggle Tips for Feature Engineering and Selection | by Gilberto Titericz | Kaggle Days Meetup Madrid](https://www.youtube.com/watch?app=desktop&v=RtqtM1UJfZc)
- [featurewiz is the best feature selection library for boosting your machine learning performance with minimal effort and maximum relevance using the famous MRMR algorithm](https://github.com/AutoViML/featurewiz)
- [Feature Ranking and Selection](https://www.youtube.com/watch?app=desktop&v=u7TVqtW7jM0)
- [Feature Engineering A-Z](https://feaz-book.com)

<!-- omit in toc -->
#### Tutorials

- [CatBoost - An In-Depth Guide](https://coderzcolumn.com/tutorials/machine-learning/catboost-an-in-depth-guide-python)
- [–í–≤–µ–¥–µ–Ω–∏–µ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É Transformers –∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—É Hugging Face](https://habr.com/ru/post/704592/)
- [Build a Telegram chatbot with any AI model under the hood](https://medium.com/@galperovich/build-a-telegram-chatbot-with-any-ai-model-under-the-hood-62f9a8675d81)
- [The Illustrated Machine Learning](https://illustrated-machine-learning.github.io/) <!--- comment -->
- [ML Primer by Boris Tseytlin](https://btseytlin.notion.site/ML-Primer-53c3d8666da1438c8eab4389321d44a2)
- [Decision Trees. The unreasonable power of nested decision rules](https://mlu-explain.github.io/decision-tree/)

<!-- omit in toc -->
### Blog posts

- [–í–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ Prod2Vec: –∫–∞–∫ –º—ã —É–ª—É—á—à–∏–ª–∏ –º–∞—Ç—á–∏–Ω–≥ –∏ –∏–∑–±–∞–≤–∏–ª–∏—Å—å –æ—Ç –∫—É—á–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤](https://habr.com/ru/company/ozontech/blog/648231/)
- [Some characteristics of best-in-class ML portfolio projects](https://mlops.systems/computervision/skillbuilding/2022/04/04/ml-portfolio-best-practices.html)
- [–ö–∞–∫ –º–µ—Ç–æ–¥ –ø–æ–¥–º–µ–Ω—ã –∑–∞–¥–∞—á–∏ –±–æ—Ä–µ—Ç—Å—è —Å –Ω–µ—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö (–∏ –º–∏—Ä–∞)](https://habr.com/ru/company/ru_mts/blog/648063/)
- [Feature Selection ‚Äî Exhaustive Overview by Danny Butvinik](https://medium.com/analytics-vidhya/feature-selection-extended-overview-b58f1d524c1c)
- [A highly anticipated Time Series Cross-validator is finally here](https://towardsdatascience.com/a-highly-anticipated-time-series-cross-validator-is-finally-here-7dc99f672736)
- [–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–¥–≤–∏–≥–∞ –¥–∞–Ω–Ω—ã—Ö: LIME, SHAP –∏ Shapley Flow](https://habr.com/ru/company/ods/blog/599573)
- [–ú–æ–µ –ø–µ—Ä–≤–æ–µ —Å–µ—Ä–µ–±—Ä–æ –Ω–∞ Kaggle –∏–ª–∏ –∫–∞–∫ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å ML –º–æ–¥–µ–ª—å –∏ –ø–æ–¥–ø—Ä—ã–≥–Ω—É—Ç—å –Ω–∞ 700 –º–µ—Å—Ç –≤–≤–µ—Ä—Ö](https://habr.com/ru/post/704440/)
- [Soccer Analytics 2022 Review](https://www.janvanhaaren.be/2022/12/29/soccer-analytics-review-2022.html)
- [–≠–π-–Ø–π, –∫—Ä–∏–ø—Ç–∞, MLOps –∏ –∫–æ–º–∞–Ω–¥–Ω—ã–π –ø–µ—Ç-–ø—Ä–æ–¥–∂–µ–∫—Ç by yorko](https://habr.com/ru/company/ods/blog/673376/)
- [Understanding UMAP](https://pair-code.github.io/understanding-umap/)
- [A new perspective on Shapley values, part I: Intro to Shapley and SHAP](https://edden-gerber.github.io/shapley-part-1/)
- [A new perspective on Shapley values, part II: The Na√Øve Shapley method](https://edden-gerber.github.io/shapley-part-2/)
- [10 –ø–µ—Ä–≤—ã—Ö –æ—à–∏–±–æ–∫ –≤ –∫–∞—Ä—å–µ—Ä–µ ML-–∏–Ω–∂–µ–Ω–µ—Ä–∞](https://habr.com/ru/post/718942/)
- [Understanding the Bias-Variance Tradeoff by Seema Singh](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)
- [The ‚ÄúBias-Variance Trade-Off‚Äù Explained Practically (In Python)](https://towardsdatascience.com/the-bias-variance-trade-off-explained-practically-in-python-48cf29d9e900)
- [–ú–æ–¥–µ–ª—å–Ω—ã–π —Ä–∏—Å–∫: –∫–∞–∫ —É–≤–µ–ª–∏—á–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã ML –º–æ–¥–µ–ª–µ–π –≤ –±–æ–ª—å—à–æ–π –∫–æ–º–ø–∞–Ω–∏–∏](https://habr.com/ru/companies/X5Tech/articles/775424/)
- [–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–Ω—Å–∞–º–±–ª–∏](https://deepschool-pro.notion.site/e0b2a0bad14e414782b9ab3dff0cd2b5)
- [Reflecting on 18 years at Google](https://ln.hixie.ch/?start=1700627373&count=1)
- [–ö–∞–∫ –Ω–µ –ø–µ—Ä–µ—Å—Ç–∞—Ç—å –±—ã—Ç—å data driven –∏–∑-–∑–∞ data driften, –∏–ª–∏ –ü–∞—Ä—É —Å–ª–æ–≤ –æ –¥—Ä–µ–π—Ñ–µ –¥–∞–Ω–Ω—ã—Ö](https://habr.com/ru/companies/glowbyte/articles/681772/)

<!-- omit in toc -->
### Other

- [StatQuest with Josh Starmer](https://www.youtube.com/@statquest/videos) <!--- comment -->
- A new perspective on Shapley values:
  - [Part I: Intro to Shapley and SHAP](https://edden-gerber.github.io/shapley-part-1/)
  - [Part II: The Na√Øve Shapley method](https://edden-gerber.github.io/shapley-part-2/)
- [Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning by Sebastian Raschka](https://arxiv.org/abs/1811.12808)  <!--- comment -->
- [How to avoid machine learning pitfalls: a guide for academic researchers by Michael A. Lones](https://arxiv.org/abs/2108.02497)
- [Core Machine Learning Skills](https://neetcode.io/practice?subpage=practice&tab=coreSkills&topic=Machine%20Learning)
- [Discover machine learning, data science & robotics competitions](https://mlcontests.com)  

## Deep Learning

<!-- omit in toc -->
### Books

- [The Little Book of Deep Learning by Fran√ßois Fleuret](https://fleuret.org/public/lbdl.pdf)
- [Deep Learning with Python by Fran√ßois Chollet](https://www.manning.com/books/deep-learning-with-python-second-edition) `paid`
- [Multimodal Deep Learning](https://slds-lmu.github.io/seminar_multimodal_dl/index.html)
- [Dive into Deep Learning](https://d2l.ai/index.html)  
I prefer going through this book using [Amazon SageMaker](https://d2l.ai/chapter_appendix-tools-for-deep-learning/sagemaker.html) <!--- comment -->
- [Understanding Deep Learning by Simon J.D. Prince](https://udlbook.github.io/udlbook/) <!--- comment -->
- [What are embeddings by Vicki Boykis](https://vickiboykis.com/what_are_embeddings/index.html) <!--- comment -->
- [Deep Learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville](https://www.deeplearningbook.org)
- [Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD by Jeremy Howard and Sylvain Gugger](https://course.fast.ai/Resources/book.html)

<!-- omit in toc -->
### Courses

- [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) `paid`
- [MIT 6.S191 Introduction to Deep Learning](http://introtodeeplearning.com/)
- [Full Stack Deep Learning - Course 2022](https://fullstackdeeplearning.com/course/2022/) <!--- comment -->
- [11-785 Introduction to Deep Learning from Carnegie Mellon University](https://www.youtube.com/playlist?list=PLp-0K3kfddPxRmjgjm0P1WT6H-gTqE8j9)
- [Neuromatch Academy: Deep Learning](https://deeplearning.neuromatch.io/tutorials/intro.html)
- [Efficient Deep Learning Systems by Yandex School of Data Analysis](https://github.com/mryab/efficient-dl-systems)
- [Short Courses by DeepLearning.AI](https://www.deeplearning.ai/short-courses/) <!--- comment -->
- [TinyML and Efficient Deep Learning Computing](https://hanlab.mit.edu/courses/2023-fall-65940) <!--- comment -->
- [Practical Deep Learning](https://course.fast.ai/)
- [Practical Deep Learning for Coders part 2: Deep Learning Foundations to Stable Diffusion](https://course.fast.ai/Lessons/part2.html)
- [PyTorch for Deep Learning & Machine Learning (video)](https://www.youtube.com/watch?v=V_xro1bcAuA) + [Learn PyTorch for Deep Learning: Zero to Mastery book (site)](https://www.learnpytorch.io/)
- [Deep Learning Fundamentals by Sebastian Raschka and Lightning AI](https://lightning.ai/pages/courses/deep-learning-fundamentals/)
- [Future of AI is Foundation Models & Self-Supervised Learning](https://www.futureofai.mit.edu/)
- [Artificial Intelligence for Beginners](https://github.com/microsoft/AI-For-Beginners)
- [11-785 Introduction to Deep Learning](https://deeplearning.cs.cmu.edu/S24/index.html) + [11785 Spring 2024 Lectures](https://www.youtube.com/playlist?list=PLp-0K3kfddPxUJzAW0KxNNjGiK_hISFas)
- [Stanford CS 230 ‚Äï Deep Learning](https://stanford.edu/~shervine/teaching/cs-230/) `cheatsheet` <!--- comment -->
  - [Convolutional Neural Networks](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)
  - [Recurrent Neural Networks](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)
  - [Deep Learning Tips and Tricks](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks)
- [CS 330: Deep Multi-Task and Meta Learning](https://cs330.stanford.edu/)
- [Deep Learning with Catalyst](https://github.com/catalyst-team/dl-course)
- [Practical DL](https://github.com/yandexdataschool/Practical_DL)
- [Deep Learning from the Foundations by fast.ai](https://course19.fast.ai/part2.html)
- [PyTorch Tutorials - Complete Beginner Course](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4)
- [–®–∫–æ–ª–∞ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è](https://dls.samcs.ru/)
- [Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html) by Andrej Karpathy <!--- comment -->

<!-- omit in toc -->
### Tutorials

- [Introduction to Deep Learning by Sebastian Raschka](https://sebastianraschka.com/blog/2021/dl-course.html#l19-self-attention-and-transformer-networks)
- [–ö–æ–ª–ª–µ–∫—Ü–∏—è —Ä—É—á–Ω—ã—Ö –∑–∞–¥–∞—á–µ–∫ –æ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö](https://fulyankin.github.io/deep_learning_masha_book/intro.html)
- [A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks by Sebastian Raschka](https://github.com/rasbt/deeplearning-models)
- [Deep Learning Tuning Playbook by Google](https://github.com/google-research/tuning_playbook)
- [A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
- [PyTorch Fundamentals by Microsoft](https://learn.microsoft.com/en-us/training/paths/pytorch-fundamentals/?wt.mc_id=aiml-26954-cxa)
- [labml.ai Annotated PyTorch Paper Implementations](https://nn.labml.ai/) <!--- comment -->
- [Grokking PyTorch](https://github.com/Kaixhin/grokking-pytorch)
- [The Incredible PyTorch](https://github.com/ritchieng/the-incredible-pytorch) <!--- comment -->
- [AI Fundamentals. Concepts, Definitions, Terms](https://aman.ai/primers/ai/?trk=feed_main-feed-card-text)
- [A Guide to Production Level Deep Learning](https://github.com/alirezadir/Production-Level-Deep-Learning?tab=readme-ov-file)
- [A Gentle Introduction to torch.autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)

<!-- omit in toc -->
### Blog posts

- [WHAT IS TORCH.NN REALLY? by Jeremy Howard, fast.ai](https://pytorch.org/tutorials/beginner/nn_tutorial.html)
- [–û ¬´—Ä–∞–∑–¥—É—Ç–æ–º –ø—É–∑—ã—Ä–µ¬ª –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π](https://habr.com/ru/post/718996/)
- [C—Ç–∞—Ç—å–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã DeepSchool](https://deepschool-pro.notion.site/9a613d3c8d3644faa8e396bd083f2bc2?v=524b15c7ce9f49d094f94cd699c2c621)
- [–ü–æ–ª–µ–∑–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø—Ä–æ PyTorch](https://telegra.ph/PyTorch-i-okolo-nego-04-12)

<!-- omit in toc -->
### Other

- [Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI](https://arxiv.org/abs/2201.00650)

## NLP

<!-- omit in toc -->
### Books

- [Natural Language Processing with Transformers](https://transformersbook.com) by Lewis Tunstall, Leandro von Werra adn Thomas Wolf
- [Speech and Language Processing by Dan Jurafsky and James H. Martin](https://web.stanford.edu/~jurafsky/slp3/)
- [Transformers for Natural Language Processing](https://www.amazon.com/Transformers-Natural-Language-Processing-architectures-ebook/dp/B09T34LVRM?ref_=ast_author_dp&dib=eyJ2IjoiMSJ9.wa38PcGXRxWshcH7rjbD4IcG9iwmHqu-ncXj6wO9_XMOVAx0cny9f6lqwV0McsOKUhvnNw-lAB6HtM35nxTl9z34_sglVNO4zrYs-3pvp9Y.-9Y0jF1BIRd4hjHermJekTA7kM2UDOJpGjgvguDKdpk&dib_tag=AUTHOR) by Denis Rothman

<!-- omit in toc -->
### Courses

- [–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞](https://stepik.org/course/54098/info)
- [Stanford CS224N: NLP with Deep Learning](https://web.stanford.edu/class/cs224n/) + [Videos](https://youtube.com/playlist?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4&si=24s4Yf3IL3fz0_Ty) + [Notes](https://vinija.ai/nlp/)
- [NLP Course | For You by Lena Voita](https://lena-voita.github.io/nlp_course.html) + [YSDA Natural Language Processing course](https://github.com/yandexdataschool/nlp_course)
- [Hugging Face course](https://huggingface.co/course/chapter0) <!--- comment -->
- [Natural Language Processing course by Valentin Malykh](https://ods.ai/tracks/nlp-course)
- [Stanford LSA 311: Computational Lexical Semantics by Dan Jurafsky](https://web.stanford.edu/~jurafsky/li15/)
- [Stanford CS224U: Natural Language Understanding](https://web.stanford.edu/class/cs224u/index.html)
- [–í–≤–µ–¥–µ–Ω–∏–µ –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞](https://compscicenter.ru/courses/introduction-nlp/2019-autumn/)
- [Stanford CS 224V Conversational Virtual Assistants with Deep Learning](https://web.stanford.edu/class/cs224v/schedule.html)
- [Learn to Love Working with Vector Embeddings by Pinecone](https://www.pinecone.io/learn/)
- [CS11-711 Advanced Natural Language Processing (at Carnegie Mellon University's Language Technology Institute)](http://www.phontron.com/class/anlp2022/) + [Video](https://youtube.com/playlist?list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z) + [Assignments](https://github.com/neubig/nlp-from-scratch-assignment-2022)
- [Linguistics for Language Technology](https://bylinina.github.io/ling_course/)

<!-- omit in toc -->
### General

- [Recommendations for Getting Started with NLP by Elvis](https://elvissaravia.substack.com/p/my-recommendations-for-getting-started)
- [–ß–∞—Ç –ø–æ NLP](https://t.me/natural_language_processing)
- [100 –≤–æ–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ NLP](https://dynamic-epoch-4bb.notion.site/100-questions-about-NLP-549ccde0d81a4689b5635888b9d0d7e6)
- [The 1950-2024 Text Embeddings Evolution Poster](https://jina.ai/news/the-1950-2024-text-embeddings-evolution-poster/)
- [awesome-nlp. A curated list of resources dedicated to Natural Language Processing](https://github.com/keon/awesome-nlp)

<!-- omit in toc -->
### Large Language Models (LLMs) / Transformers

- [Stanford Webinar - GPT-3 & Beyond](https://youtu.be/-lnHHWRCDGk)
- [Transformer Recipe by Elvis Saravia](https://github.com/dair-ai/Transformers-Recipe)
- [Transformer, explained in detail by Igor Kotenkov](https://youtu.be/iOrNbK2T92M)
- [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
- [State of GPT by Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)
- [LLM University by Cohere](https://docs.cohere.com/docs/llmu) <!--- comment -->
- [CS324 - Large Language Models](https://stanford-cs324.github.io/winter2022/)
- [Generative AI exists because of the transformer. This is how it writes](https://ig.ft.com/generative-ai/)
- [Training & Fine-Tuning LLMs for Production](https://learn.activeloop.ai/courses/llms)
- [LLMOps: Building Real-World Applications With Large Language Models](https://www.comet.com/production/site/llm-course/?utm_source=llm_course&utm_campaign=svpino)
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [Transformers Tutorials](https://github.com/nielsrogge/transformers-tutorials)
- [Ruformers/–†—É—Ñ–æ—Ä–º–µ—Ä—ã](https://github.com/AlexeyMalafeev/ruformers)
- [–°—Ö–µ–º–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä](https://github.com/pa-shk/transformer-encoder)
- [Large Language Model Course](https://github.com/mlabonne/llm-course) <!--- comment -->
- [Insights from Finetuning LLMs with Low-Rank Adaptation by Sebastian Raschka](https://youtu.be/rgmJep4Sba4?si=xyRU4LUSkzUkCBFM)
- [LLM Bootcamp - Spring 2023](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)
- [ChatGPT Course ‚Äì Use The OpenAI API to Code 5 Projects](https://www.youtube.com/watch?v=uRQH2CFvedY)
- [Self-Attention & Transformers (CS 224n: Natural Language Processing with Deep Learning)](https://web.stanford.edu/class/cs224n/readings/cs224n-self-attention-transformers-2023_draft.pdf)
- [Build a Large Language Model (From Scratch) by Sebastian Raschka](https://github.com/rasbt/LLMs-from-scratch)
- [Hands-on LLMs Course](https://github.com/iusztinpaul/hands-on-llms)
- [LLaMA-Factory. Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)](https://github.com/hiyouga/LLaMA-Factory)
- [Open LLMs. A list of open LLMs available for commercial use](https://github.com/eugeneyan/open-llms)
- [Overview of Large Language Models](https://aman.ai/primers/ai/LLM/?trk=feed_main-feed-card-text)
- [Mastering RAG: How To Architect An Enterprise RAG System](https://www.rungalileo.io/blog/mastering-rag-how-to-architect-an-enterprise-rag-system)
- [–ò—Å—á–µ—Ä–ø—ã–≤–∞—é—â–∏–π –≥–∞–π–¥ –ø–æ –æ–ø–µ–Ω—Å–æ—Ä—Å–Ω—ã–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º](https://skillbox.ru/media/code/ischerpyvayushchiy-gayd-po-opensorsnym-yazykovym-modelyam/#stk-8)
- [Open-Source AI Cookbook](https://huggingface.co/learn/cookbook/index)
- [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html)
- [LLM Visualization](https://bbycroft.net/llm)
- [The Illustrated Transformer by Jay Alammar](https://jalammar.github.io/illustrated-transformer/)
- [Learn to Train and Deploy a Real-Time Financial Advisor](https://github.com/iusztinpaul/hands-on-llms)
- [The Annotated Transformer](https://github.com/harvardnlp/annotated-transformer/blob/master/AnnotatedTransformer.ipynb) + [Neural networks by 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Build a Large Language Model (From Scratch)](https://github.com/rasbt/LLMs-from-scratch)
- [Elicit Machine Learning Reading List](https://github.com/elicit/machine-learning-list)

<!-- omit in toc -->
### Reading papers with AI

- [Explainpaper](https://www.explainpaper.com/)
- [ChatPDGF](https://www.chatpdf.com/)
- [Reimagine Research](https://www.researchrabbit.ai)
- [Discover scientific knowledge and stay connected to the world of science](https://www.researchgate.net)
- [Get scientific answers by asking millions of research papers](https://scienceos.ai)

<!-- omit in toc -->
### Prompt Engineering

- [Prompt Engineering Guide](https://www.promptingguide.ai/) + [Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide) <!--- comment -->
- [Prompt injection with Gandalf](https://gandalf.lakera.ai/)
- [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)
- [Prompt Engineering Guide](https://learnprompting.org/docs/intro) <!--- comment -->
- [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts) <!--- comment -->
- [Advanced Prompt Engineering](https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01)
- [Prompt engineering Guide by Open.ai](https://platform.openai.com/docs/guides/prompt-engineering) <!--- comment -->
- [Prompt Of The Year: 2023](https://github.com/successfulstudy/promptoftheyear/tree/main)

<!-- omit in toc -->
### Tutorials

- [Train and Fine-Tune Sentence Transformers Models](https://huggingface.co/blog/how-to-train-sentence-transformers)
- [Working With Text Data using Sklearn](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#extracting-features-from-text-files) + [Text feature extraction using Sklearn](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)
- [minbpe. Minimal, clean code for the (byte-level) Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization](https://github.com/karpathy/minbpe)

<!-- omit in toc -->
### Blog posts

- [–ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è](https://newtechaudit.ru/multiklassifikacziya-ekstremalno-korotkih-tekstov-klassicheskimi-metodami-mashinnogo-obucheniya/)
- [–†–µ–π—Ç–∏–Ω–≥ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π](https://habr.com/ru/post/669674/)
- [–ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è, –æ –∫–æ—Ç–æ—Ä—ã—Ö –º—ã —É–∑–Ω–∞–ª–∏ 5 –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥](https://habr.com/ru/company/tinkoff/blog/696756/)
- [–°–∞–º–∞—è –±–æ–ª—å—à–∞—è BERT-–ø–æ–¥–æ–±–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–º–µ—Å—Ç–∏—Ç—Å—è –Ω–∞ –≤–∞—à –∫–æ–º–ø—å—é—Ç–µ—Ä](https://habr.com/ru/company/yandex/blog/688234/)
- [ChatGPT –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞: —Ä–µ—à–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É](https://habr.com/ru/company/ods/blog/709222/)
- [GPT in 60 Lines of NumPy](https://jaykmody.com/blog/gpt-from-scratch)
- [What Is ChatGPT Doing ‚Ä¶ and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)
- [From GPT-3 to ChatGPT: Training Language Models on Instructions and Human Feedback](https://youtu.be/2JxcIy7AgFQ)
- [–ö—Ç–æ —Ç–∞–∫–∏–µ LLM-–∞–≥–µ–Ω—Ç—ã –∏ —á—Ç–æ –æ–Ω–∏ —É–º–µ—é—Ç?](https://habr.com/ru/companies/ods/articles/776478/)

<!-- omit in toc -->
### Articles

- [Word2Vec](https://arxiv.org/pdf/1301.3781.pdf), Mikolov et al., Efficient Estimation of Word Representations in Vector Space
- [FastText](https://arxiv.org/pdf/1607.04606.pdf), Bojanowski et al., Enriching Word Vectors with Subword Information
- [Attention](https://arxiv.org/abs/1409.0473), Bahdanau et al., Neural Machine Translation by Jointly Learning to Align and Translate
- [Transformers](https://arxiv.org/abs/1706.03762), Vaswani et al., Attention Is All You Need
- [BERT](https://arxiv.org/abs/1810.0480), Devlin et al., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
- [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), Radford et al., Language Models are Unsupervised Multitask Learners
- [GPT-3](https://arxiv.org/abs/2005.14165), Brown et al, Language Models are Few-Shot Learners
- [LaBSE](https://arxiv.org/abs/2007.01852), Feng et al., Language-agnostic BERT Sentence Embedding
- [CLIP](https://arxiv.org/abs/2103.00020), Radford et al., Learning Transferable Visual Models From Natural Language Supervision
- [RoPE](https://arxiv.org/abs/2104.09864), Su et al., RoFormer: Enhanced Transformer with Rotary Position Embedding
- [LoRA](https://arxiv.org/abs/2106.09685), Hu et al., LoRA: Low-Rank Adaptation of Large Language Models
- [InstructGPT](https://arxiv.org/abs/2203.02155), Ouyang et al., Training language models to follow instructions with human feedback
- [Scaling laws](https://arxiv.org/abs/2203.15556), Hoffmann et al., Training Compute-Optimal Large Language Models
- [FlashAttention](https://arxiv.org/abs/2205.14135), Dao et al., FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
- [NLLB](https://arxiv.org/abs/2207.04672), NLLB team, No Language Left Behind: Scaling Human-Centered Machine Translation
- [Q8](https://arxiv.org/abs/2208.07339), Dettmers et al., LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale
- [Self-instruct](https://arxiv.org/abs/2212.10560), Wang et al., Self-Instruct: Aligning Language Models with Self-Generated Instructions
- [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html), Taori et al., Alpaca: A Strong, Replicable Instruction-Following Model
- [LLaMA](https://arxiv.org/abs/2302.13971), Touvron, et al., LLaMA: Open and Efficient Foundation Language Models

## Computer Vision

- [–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ](https://stepik.org/course/50352/info)
- [CS231n: Deep Learning for Computer Vision](http://cs231n.stanford.edu/schedule.html) + [Videos](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&ab_channel=StanfordUniversitySchoolofEngineering)
- [EECS 442: Computer Vision](https://web.eecs.umich.edu/~justincj/teaching/eecs442/WI2021/) + [Videos](https://m.bilibili.com/video/BV1BV411n7Km)
- [Foundations of Computer Vision by Antonio Torralba, Phillip Isola and William T. Freeman](https://mitpress.mit.edu/9780262048972/foundations-of-computer-vision/)

## Graphs

- [CS224W: Machine Learning with Graphs](https://web.stanford.edu/class/cs224w/) + [Video](https://www.youtube.com/playlist?list=PLoROMvodv4rOP-ImU-O1rYRg2RFxomvFp) <!--- comment -->
- [Graph Neural Networks for RecSys](https://aman.ai/recsys/gnn/)
- [Graph Neural Networks](https://aman.ai/primers/ai/gnn/)

## Reinforcement Learning

- [Spinning Up in Deep RL](https://spinningup.openai.com/en/latest/index.html) `course` <!--- comment -->
- [ü§ó Deep Reinforcement Learning Course](https://huggingface.co/learn/deep-rl-course/unit0/introduction) `course`
- [Practical RL](https://github.com/yandexdataschool/Practical_RL)

## RecSys

<!-- omit in toc -->
### Courses

- [Your first recsys by MTS](https://ods.ai/tracks/mts-recsys-df2020) `course`
- [Your Second RecSys by MTS](https://ods.ai/tracks/recsys-course2021) `course`
- [–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã](https://github.com/shashist/recsys-course)

<!-- omit in toc -->
### Books

- –ö. –§–∞–ª—å–∫. [–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ](https://dmkpress.com/catalog/computer/data/978-5-97060-774-9/) / [Practical Recommender Systems](https://www.manning.com/books/practical-recommender-systems) by Kim Falk <!--- comment -->
- [Personalized Machine Learning](https://cseweb.ucsd.edu/~jmcauley/pml/)

<!-- omit in toc -->
### Other

- [–ê–≤–∏—Ç–æ. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏](https://youtu.be/zopTexr7gfY?si=7yGMorHG_PZpTUKv)
- [Recommenders. Best Practices on Recommendation Systems](https://github.com/recommenders-team/recommenders)
- [–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã](https://education.yandex.ru/knowledge/rekomendatelnye-sistemy.-mashinnoe-obuchenie)
- [–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã: –∏–¥–µ–∏, –ø–æ–¥—Ö–æ–¥—ã, –∑–∞–¥–∞—á–∏](https://habr.com/ru/companies/jetinfosystems/articles/453792/)

## Time Series

- [–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã](https://education.yandex.ru/handbook/ml/article/vremennye-ryady)
- [Topic 9. Time Series Analysis with Python](https://mlcourse.ai/book/topic09/topic09_intro.html)
- [–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤](https://education.yandex.ru/knowledge/prognozirovanie-vremennyh-ryadov.-mashinnoe-obuchenie)
- [Time Series](https://www.kaggle.com/learn/time-series)
- [Forecasting time series with gradient boosting: Skforecast, XGBoost, LightGBM, Scikit-learn and CatBoost](https://cienciadedatos.net/documentos/py39-forecasting-time-series-with-skforecast-xgboost-lightgbm-catboost) by Joaqu√≠n Amat Rodrigo, Javier Escobar Ortiz
- [ARIMA and SARIMAX models with Python](https://cienciadedatos.net/documentos/py51-arima-sarimax-models-python.html) by Joaqu√≠n Amat Rodrigo, Javier Escobar Ortiz
- –ì—Ä—É–∑–¥–µ–≤ –ê.–í., –†–∞—Ñ—Ñ–µ—Ä—Ç–∏ –ì. [–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –ø–æ–º–æ—â—å—é Prophet, sktime, ETNA –∏ Greykite](https://dmkpress.com/catalog/computer/data/978-5-93700-212-9/)

## Big Data

<!-- omit in toc -->
### Books

- –ü–µ—Ä—Ä–µ–Ω –ñ.–ñ. [Spark –≤ –¥–µ–π—Å—Ç–≤–∏–∏](https://dmkpress.com/catalog/computer/data/978-5-97060-879-1/) / [Spark in Action](https://www.manning.com/books/spark-in-action-second-edition) by Jean-Georges Perrin
- [Learning Spark](https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf)
- [Data Analysis with Python and PySpark](https://www.manning.com/books/data-analysis-with-python-and-pyspark) <!--- comment -->

<!-- omit in toc -->
### Other

- [–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ Spark](https://www.youtube.com/watch?v=McXK_ObP00c)
- [–ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å Apache Spark](https://datalearn.ru/kurs-po-getting-start-with-data-engineering)
- [PySpark –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞. –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–æ—Å–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã –∏ –∫–∞–∫ –ø–æ–Ω—è—Ç—å, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ –±—Ä–∞—Ç—å](https://habr.com/ru/companies/avito/articles/732870/?erid=2VtzqxjG1Yk&erid=2Vtzqwxo44G)
- [PySpark –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞. –ö–∞–∫ –≤—ã–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é toPandas –∏ –µ–≥–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤](https://habr.com/ru/companies/avito/articles/740232/)
- [Spark Architecture by FaangTalk](https://www.youtube.com/watch?v=1nzLD5VZE4I&t=132s)
- [SPARK –¥–ª—è ¬´–º–∞–ª—ã—à–µ–π¬ª](https://habr.com/ru/companies/alfa/articles/808415/)
